# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KuvCh3Xy029txp6Hiwz2I4aQP0QwMmDS

#**Data Understanding**
"""

!pip install -q kaggle

from google.colab import files
files.upload()

# Commented out IPython magic to ensure Python compatibility.
# library for data loading and data analysis
import pandas as pd
import numpy as np

# library for data visualization
from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline

!mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d karkavelrajaj/amazon-sales-dataset

! mkdir amazon-sales-dataset

! unzip amazon-sales-dataset.zip -d amazon-sales-dataset

amazonSales = pd.read_csv('amazon-sales-dataset/amazon.csv')
amazonSales

"""#**Data Preparation**"""

amazonSales.info()

# Clean dan Convert data Rating
def clean_and_convert(value):
    if value == '|':
        return None  # Merubah valu "|" menjadi kosong
    else:
        return float(value)

# Clean and convert the 'rating' column
amazonSales['rating'] = amazonSales['rating'].apply(clean_and_convert)

print(amazonSales['rating'])
print(amazonSales['rating'].dtypes)

# Mengecek kembali variabel amazonSales
amazonSales.info()

# Mengecek kembali missing value pada variabel amazonSales
amazonSales.isnull().sum()

all_amazonSales_clean = amazonSales.dropna()
all_amazonSales_clean

all_amazonSales_clean.isnull().sum()

amazonSales_category = all_amazonSales_clean.loc[:, ['product_id', 'product_name', 'category']]
amazonSales_category

# Mengecek kembali missing value pada variabel amazonSales
amazonSales_category.isnull().sum()

# Mengurutkan product berdasarkan product_id kemudian memasukkannya ke dalam variabel fix_amazonSales_category
fix_amazonSales_category = amazonSales_category.sort_values('product_id', ascending=True)
fix_amazonSales_category

# Mengecek berapa jumlah fix_amazonSales_category
len(fix_amazonSales_category.product_id.unique())

# Mengecek kategori produk yang unik
fix_amazonSales_category.category.unique()

# Membuat variabel preparation yang berisi dataframe fix_amazonSales_category kemudian mengurutkan berdasarkan product_id
preparation = fix_amazonSales_category
preparation.sort_values('product_id')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('product_id')
preparation

# Mengonversi data series product_id menjadi dalam bentuk list
product_id = preparation['product_id'].tolist()

# Mengonversi data series product_name menjadi dalam bentuk list
product_name = preparation['product_name'].tolist()

# Mengonversi data series category menjadi dalam bentuk list
category = preparation['category'].tolist()

print(len(product_id))
print(len(product_name))
print(len(category))

# Membuat dictionary untuk data product_id, product_name, dan category
new_amazonSales_category = pd.DataFrame({
    'product_id': product_id,
    'product_name': product_name,
    'category': category
})
new_amazonSales_category

"""#**Model Development dengan Content Based Filtering**"""

data = new_amazonSales_category
data.sample(5)

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data category
tf.fit(data['category'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['category'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan kategori produk
# Baris diisi dengan nama produk

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.product_name
).sample(22, axis=1).sample(10, axis=0)

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama produk
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['product_name'], columns=data['product_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap produk
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def product_recommendations(product_name, similarity_data=cosine_sim_df, items=data[['product_name', 'category']], k=5):
    """
    Rekomendasi Product berdasarkan kemiripan dataframe

    Parameter:
    ---
    product_name : tipe data string (str)
                Nama produk (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan produk sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,product_name].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop product_name agar nama produk yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(product_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

data[data.product_name.eq('Wayona Nylon Braided USB to Lightning Fast Charging and Data Sync Cable Compatible for iPhone 13, 12,11, X, 8, 7, 6, 5, iPad Air, Pro, Mini (3 FT Pack of 1, Grey)')]

# Mendapatkan rekomendasi produk yang mirip dengan produk yang dimasukkan pada product_recommendations.
product_recommendations('Wayona Nylon Braided USB to Lightning Fast Charging and Data Sync Cable Compatible for iPhone 13, 12,11, X, 8, 7, 6, 5, iPad Air, Pro, Mini (3 FT Pack of 1, Grey)')

"""#**Model Development dengan Collaborative Filtering**

#**Data Understanding**
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

df = all_amazonSales_clean.loc[:, ['product_id', 'product_name', 'rating', 'user_id']]
df

"""#**Data Preparation**"""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding user_id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

# Mengubah product_id menjadi list tanpa nilai yang sama
product_ids = df['product_id'].unique().tolist()

# Melakukan proses encoding product_id
product_to_product_encoded = {x: i for i, x in enumerate(product_ids)}

# Melakukan proses encoding angka ke product_id
product_encoded_to_product = {i: x for i, x in enumerate(product_ids)}

# Mapping userID ke dataframe user
df['user'] = df['user_id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe produk
df['product'] = df['product_id'].map(product_to_product_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah product
num_products = len(product_encoded_to_product)
print(num_products)

# Mengubah atau memastikkan kalau rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Product: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_products, min_rating, max_rating
))

"""#**Membagi Data untuk Training dan Validasi**"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan produk menjadi satu value
x = df[['user', 'product']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""#**Proses Training**"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_products, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_products = num_products
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.products_embedding = layers.Embedding( # layer embeddings product
        num_products,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.products_bias = layers.Embedding(num_products, 1) # layer embedding product bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    products_vector = self.products_embedding(inputs[:, 1]) # memanggil layer embedding 3
    products_bias = self.products_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_product = tf.tensordot(user_vector, products_vector, 2)

    x = dot_user_product + user_bias + products_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_products, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""#**Visualisasi Metrik**"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#**Mendapatkan Rekomendasi Produk**"""

products_df = new_amazonSales_category
df = all_amazonSales_clean.loc[:, ['product_id', 'product_name', 'rating', 'user_id']]

# Mengambil sample user
user_id = df.user_id.sample(1).iloc[0]
products_experienced_by_user = df[df.user_id == user_id]

products_not_experienced = products_df[~products_df['product_id'].isin(products_experienced_by_user.product_id.values)]['product_id']
products_not_experienced = list(
    set(products_not_experienced)
    .intersection(set(product_to_product_encoded.keys()))
)

products_not_experienced = [[product_to_product_encoded.get(x)] for x in products_not_experienced]
user_encoder = user_to_user_encoded.get(user_id)
user_product_array = np.hstack(
    ([[user_encoder]] * len(products_not_experienced), products_not_experienced)
)

ratings = model.predict(user_product_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_products_ids = [
    product_encoded_to_product.get(products_not_experienced[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Products with high ratings from user')
print('----' * 8)

top_products_user = (
    products_experienced_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .product_id.values
)

products_df_rows = products_df[products_df['product_id'].isin(top_products_user)]
for row in products_df_rows.itertuples():
    print(row.product_name, ':', row.category)

print('----' * 8)
print('Top 10 Products recommendation')
print('----' * 8)

recommended_products = products_df[products_df['product_id'].isin(recommended_products_ids)]
for row in recommended_products.itertuples():
    print(row.product_name, ':', row.category)